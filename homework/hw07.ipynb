{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b9370b-e52d-485b-81bd-8bd7aa49b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType, StringType, StructField, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb59f05-0367-42e5-9244-1eb09257e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53372568-1505-4ade-9130-88002be18871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://4580aa86c773:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff8115bf10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad716c9b-fe2d-4d5a-bcfc-198caf32ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c2434d2-6392-4d45-9cf8-cfbe4b29e167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='Date', _c1='Location', _c2='MinTemp', _c3='MaxTemp', _c4='Rainfall', _c5='Evaporation', _c6='Sunshine', _c7='WindGustDir', _c8='WindGustSpeed', _c9='WindDir9am', _c10='WindDir3pm', _c11='WindSpeed9am', _c12='WindSpeed3pm', _c13='Humidity9am', _c14='Humidity3pm', _c15='Pressure9am', _c16='Pressure3pm', _c17='Cloud9am', _c18='Cloud3pm', _c19='Temp9am', _c20='Temp3pm', _c21='RainToday', _c22='RainTomorrow'),\n",
       " Row(_c0='2008-12-01', _c1='Albury', _c2='13.4', _c3='22.9', _c4='0.6', _c5='NA', _c6='NA', _c7='W', _c8='44', _c9='W', _c10='WNW', _c11='20', _c12='24', _c13='71', _c14='22', _c15='1007.7', _c16='1007.1', _c17='8', _c18='NA', _c19='16.9', _c20='21.8', _c21='No', _c22='No'),\n",
       " Row(_c0='2008-12-02', _c1='Albury', _c2='7.4', _c3='25.1', _c4='0', _c5='NA', _c6='NA', _c7='WNW', _c8='44', _c9='NNW', _c10='WSW', _c11='4', _c12='22', _c13='44', _c14='25', _c15='1010.6', _c16='1007.8', _c17='NA', _c18='NA', _c19='17.2', _c20='24.3', _c21='No', _c22='No')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fda304a-629d-4509-b8e1-ec3125d4da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "  StructField(\"Date\", StringType(), False),\n",
    "  StructField(\"Location\", StringType(), False),\n",
    "  StructField(\"MinTemp\", DoubleType(), False),\n",
    "  StructField(\"MaxTemp\", DoubleType(), False),\n",
    "  StructField(\"Rainfall\", DoubleType(), False),\n",
    "  StructField(\"Evaporation\", DoubleType(), False),\n",
    "  StructField(\"Sunshine\", DoubleType(), False),\n",
    "  StructField(\"WindGustDir\", StringType(), False),\n",
    "  StructField(\"WindGustSpeed\", DoubleType(), False),\n",
    "  StructField(\"WindDir9am\", StringType(), False),\n",
    "  StructField(\"WindDir3pm\", StringType(), False),\n",
    "  StructField(\"WindSpeed9am\", DoubleType(), False),\n",
    "  StructField(\"WindSpeed3pm\", DoubleType(), False),\n",
    "  StructField(\"Humidity9am\", DoubleType(), False),\n",
    "  StructField(\"Humidity3pm\", DoubleType(), False),\n",
    "  StructField(\"Pressure9am\", DoubleType(), False),\n",
    "  StructField(\"Pressure3pm\", DoubleType(), False),\n",
    "  StructField(\"Cloud9am\", DoubleType(), False), \n",
    "  StructField(\"Cloud3pm\", DoubleType(), False),\n",
    "  StructField(\"Temp9am\", DoubleType(), False),\n",
    "  StructField(\"Temp3pm\", DoubleType(), False),\n",
    "  StructField(\"RainToday\", StringType(), False),\n",
    "  StructField(\"RainTomorrow\", StringType(), False)\n",
    " \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c46507-0158-41cf-beeb-40dbb93a9b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = spark.read.format(\"csv\").schema(schema).load(\"weatherAUS.csv\")\n",
    "cols = dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fefcaa85-8b2e-4cb7-b958-65a1859284c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Date: string, Location: string, MinTemp: double, MaxTemp: double, Rainfall: double, Evaporation: double, Sunshine: double, WindGustDir: string, WindGustSpeed: double, WindDir9am: string, WindDir3pm: string, WindSpeed9am: double, WindSpeed3pm: double, Humidity9am: double, Humidity3pm: double, Pressure9am: double, Pressure3pm: double, Cloud9am: double, Cloud3pm: double, Temp9am: double, Temp3pm: double, RainToday: string, RainTomorrow: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45ee2c2b-fc25-4c9a-9672-55670a8c68c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinTemp</th>\n",
       "      <td>1486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxTemp</th>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rainfall</th>\n",
       "      <td>3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaporation</th>\n",
       "      <td>62791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunshine</th>\n",
       "      <td>69836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindGustDir</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <td>10264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindDir9am</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindDir3pm</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <td>1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <td>3063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity9am</th>\n",
       "      <td>2655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity3pm</th>\n",
       "      <td>4508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pressure9am</th>\n",
       "      <td>15066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pressure3pm</th>\n",
       "      <td>15029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud9am</th>\n",
       "      <td>55889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud3pm</th>\n",
       "      <td>59359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp9am</th>\n",
       "      <td>1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp3pm</th>\n",
       "      <td>3610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RainToday</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RainTomorrow</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "Date               0\n",
       "Location           0\n",
       "MinTemp         1486\n",
       "MaxTemp         1262\n",
       "Rainfall        3262\n",
       "Evaporation    62791\n",
       "Sunshine       69836\n",
       "WindGustDir        0\n",
       "WindGustSpeed  10264\n",
       "WindDir9am         0\n",
       "WindDir3pm         0\n",
       "WindSpeed9am    1768\n",
       "WindSpeed3pm    3063\n",
       "Humidity9am     2655\n",
       "Humidity3pm     4508\n",
       "Pressure9am    15066\n",
       "Pressure3pm    15029\n",
       "Cloud9am       55889\n",
       "Cloud3pm       59359\n",
       "Temp9am         1768\n",
       "Temp3pm         3610\n",
       "RainToday          0\n",
       "RainTomorrow       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get count of nan or missing values in pyspark\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "null_val=dataset.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in dataset.columns])\n",
    "\n",
    "null_val.toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d509c9-fa6d-419b-9e05-9f039c16c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_df=dataset.drop(\"Location\",\"Date\", \"Evaporation\",\"Sunshine\",\"WindGustSpeed\",\"Pressure9am\",\"Pressure3am\",\n",
    "                      \"Cloud9am\",\"Cloud3am\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "258067e9-7d08-4106-be8c-29d10d2fdf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_df=process_df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0243bfe-165d-4b2a-9bb3-a265f35ca695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    " \n",
    "from distutils.version import LooseVersion\n",
    " \n",
    "categoricalColumns = [ \"WindGustDir\", \"WindDir9am\",\"WindDir3pm\",\"RainToday\"]\n",
    "stages = [] # stages in Pipeline\n",
    "for categoricalCol in categoricalColumns:\n",
    "    \n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    \n",
    "    if LooseVersion(pyspark.__version__) < LooseVersion(\"3.0\"):\n",
    "        from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "        encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    else:\n",
    "        from pyspark.ml.feature import OneHotEncoder\n",
    "        encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14061d0e-a065-4621-a28a-fe1b25b2e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol=\"RainTomorrow\", outputCol=\"label\")\n",
    "stages += [label_stringIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df0ee9ca-1f8f-46ca-b477-27ee91a2ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols = [ 'MinTemp', 'MaxTemp','Rainfall', 'WindSpeed9am', \n",
    "               'WindSpeed3pm', 'Humidity9am', 'Humidity3pm','Temp9am','Temp3pm']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0ee3969-73ed-4ca4-b1fd-88680f0c286d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "  \n",
    "partialPipeline = Pipeline().setStages(stages)\n",
    "pipelineModel = partialPipeline.fit(process_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1959aa36-0403-4d61-ab90-f3028355da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preppedDataDF = pipelineModel.transform(process_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3295320-2d7d-423f-8eb1-87bea5cd8f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65089\n",
      "16486\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = preppedDataDF.randomSplit([0.8, 0.2], seed=12345)\n",
    "print(trainingData.count())\n",
    "print(testData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6c5c749-f441-4990-a099-488c55e07bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92f042fc-8528-40bd-a4a0-04d483802835",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtModel = dt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c953ab58-d76d-4f3d-828f-4543b00b0575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numNodes =  35\n",
      "depth =  5\n"
     ]
    }
   ],
   "source": [
    "print(\"numNodes = \", dtModel.numNodes)\n",
    "print(\"depth = \", dtModel.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e30a0a8a-05cb-4ad7-8b2c-1280ebc699a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_56f3eea50af3, depth=5, numNodes=35, numClasses=3, numFeatures=58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dtModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a94ce2f-5ec2-4c52-a78c-fb045e47db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81cb54c4-6e14-4769-984d-7a0c2d37343d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, probability: vector, prediction: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected = predictions.select(\"label\",\"probability\", \"prediction\")\n",
    "display(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e070d16-11bc-4c13-be36-fc87c40f1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Evaluate model\n",
    "evaluator= RegressionEvaluator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4be88481-de0b-4765-a708-2c0363ca0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "dtparamGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [3, 5, 7])\n",
    "             .addGrid(dt.maxBins, [5, 10, 15])\n",
    "             .addGrid(dt.minInfoGain, [0.0, 0.2, 0.4])\n",
    "             .addGrid(dt.impurity, ['gini', 'entropy'])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d47608eb-e318-4d83-b0a3-83ee7753aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcv = CrossValidator(estimator = dt ,\n",
    "                      estimatorParamMaps = dtparamGrid,\n",
    "                      evaluator = evaluator,\n",
    "                      numFolds = 4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0b72d52-00a4-4b81-b77d-729e7fe54af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcvModel = dtcv.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21285566-cc1b-4043-bd8d-8155a8f0a54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param (maxDepth):  5\n",
      "Best Param (impurity):  gini\n",
      "Best Param (maxBins):  15\n",
      "Best Param (minInfoGain):  0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bestModel = dtcvModel.bestModel\n",
    "print( 'Best Param (maxDepth): ', bestModel._java_obj.depth())\n",
    "print( 'Best Param (impurity): ', bestModel._java_obj.getImpurity())\n",
    "print( 'Best Param (maxBins): ', bestModel._java_obj.getMaxBins())\n",
    "print( 'Best Param (minInfoGain): ', bestModel._java_obj.getMinInfoGain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02833ab3-2f98-4fac-a9d8-45f700f33edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtcvModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bd29fb7-328b-4afc-a4e4-7fc6bd5b93c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44726784595148283"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "207986f0-5b55-4877-9776-021b3dcc924a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "regressionEvaluator = RegressionEvaluator(\n",
    "predictionCol=\"prediction\",\n",
    "labelCol=\"label\",\n",
    "metricName=\"rmse\")\n",
    "rmse = regressionEvaluator.evaluate(predictions)\n",
    "print(f\"RMSE is {rmse:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f175d77f-65ca-4c92-9721-f459110c296a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
